# -*- coding: utf-8 -*-
"""babuwolf.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eE7wTD1tdv8zb4MFM83vRUk4UrZ-a9zw
"""

import requests
import time
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from keras.layers import Input, Bidirectional, LSTM, Attention, BatchNormalization, Dense, LeakyReLU
from keras.losses import mean_squared_error
from keras.metrics import RootMeanSquaredError
from keras.optimizers.legacy import Adam
import tensorflow as tf
from sklearn.preprocessing import StandardScaler, MinMaxScaler






BASE_URL = 'https://www.alphavantage.co/query?'
API_KEY = 'K37TOUDE2WB29LQJ'

BATCH_SIZE = 300
n_steps = 64
n_features = 33
epoch = 2


def get_exchange_rate(k):
    # Frequency of the sine wave (in cycles per unit time)
    noise_level=np.random.rand()
    trend=np.random.rand()
    freq = np.random.rand()

    # Amplitude of the sine wave
    amplitude = np.random.randn()

    # Generate time series data using sine wave
    exchange_rate = amplitude * np.sin(freq * (k%30)) + trend * (k%20)

    # Add noise to the data
    exchange_rate += noise_level * np.random.randn()

    # Return the synthetic exchange rate data
    return pd.DataFrame({'exchange_rate': exchange_rate}, index=[k])


from keras.models import Sequential
from keras.layers import LSTM, Bidirectional, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, Activation, Add
from keras.optimizers import Adam
from keras.regularizers import l2
from keras.activations import Swish
from keras.initializers import he_normal

def create_advanced_lstm_model(n_steps, n_features):
    model = Sequential()

    # Convolutional Layers
    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_steps, n_features)))
    model.add(MaxPooling1D(pool_size=2))
    model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))
    model.add(MaxPooling1D(pool_size=2))
    model.add(Flatten())

    # LSTM Layers with Attention
    model.add(LSTM(units=128, return_sequences=True))
    # model.add(AttentionLayer())  # Custom attention layer

    model.add(LSTM(units=64, return_sequences=True))
    # model.add(AttentionLayer())

    # Residual Connection
    residual = LSTM(units=64, return_sequences=True)(model.layers[-1].output)
    model.add(Add()([model.layers[-1].output, residual]))

    # Regularization and Batch Normalization
    model.add(Dropout(0.5))
    model.add(BatchNormalization())

    # Fully Connected Layers
    model.add(Dense(64, activation=Swish(), kernel_initializer=he_normal(), kernel_regularizer=l2(0.01)))
    model.add(Dense(n_steps, activation='softmax'))

    # Compilation
    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])
    return model

# Assuming n_steps, n_features, n_classes are defined
# model = create_advanced_lstm_model(n_steps, n_features, n_classes)



def splitsequence(data, n_steps, n_features):
    X, y = [], []
    for i in range(n_steps, data.shape[0]-n_steps):
        X.append(data.iloc[i-n_steps:i, :].values)
        y.append(data.iloc[i:i+n_steps, [0]].values)
    X, y = np.array(X), np.array(y)
    X = X.reshape(X.shape[0], n_steps, n_features)
    y = y.reshape(y.shape[0], n_steps, 1)
    return X, y


def plot_predictions(predictions, data):
    plt.figure(figsize=(10, 7))
    plt.plot(np.arange(0, len(data)), data,
             color='red', label="exchange_rate")
    plt.plot(np.arange(len(data)-1, -1+len(data) + len(predictions)),
             predictions, color='green', label='future')
    plt.legend()
    plt.show(block=False)
    plt.pause(0.09)
    plt.close()


def create_data_model(df):
    data_model = pd.DataFrame(
        df['exchange_rate'], index=df.index, columns=["exchange_rate"])
    data_model = pd.concat(
        [data_model, calculate_moving_average(df['exchange_rate'], 2)], axis=1)
    data_model = pd.concat(
        [data_model, calculate_moving_average(df['exchange_rate'], 3)], axis=1)
    data_model = pd.concat(
        [data_model, calculate_moving_average(df['exchange_rate'], 5)], axis=1)
    data_model = pd.concat(
        [data_model, calculate_moving_average(df['exchange_rate'], 8)], axis=1)
    data_model = pd.concat(
        [data_model, calculate_moving_average(df['exchange_rate'], 13)], axis=1)
    data_model = pd.concat(
        [data_model, calculate_moving_average(df['exchange_rate'], 21)], axis=1)
    data_model = pd.concat(
        [data_model, calculate_moving_average(df['exchange_rate'], 34)], axis=1)
    data_model = pd.concat(
        [data_model, calculate_moving_average(df['exchange_rate'], 55)], axis=1)
    data_model = pd.concat(
        [data_model, calculate_relative_strength_index(df['exchange_rate'], 9)], axis=1)
    data_model = pd.concat(
        [data_model, calculate_relative_strength_index(df['exchange_rate'], 14)], axis=1)
    data_model = pd.concat(
        [data_model, calculate_relative_strength_index(df['exchange_rate'], 23)], axis=1)
    data_model = pd.concat(
        [data_model, calculate_relative_strength_index(df['exchange_rate'], 37)], axis=1)
    data_model = pd.concat(
        [data_model, calculate_bollinger_bands(df['exchange_rate'], 10)], axis=1)
    data_model = pd.concat(
        [data_model, calculate_bollinger_bands(df['exchange_rate'], 20)], axis=1)
    data_model = pd.concat(
        [data_model, calculate_bollinger_bands(df['exchange_rate'], 30)], axis=1)
    data_model = pd.concat(
        [data_model, calculate_bollinger_bands(df['exchange_rate'], 50)], axis=1)
    data_model = pd.concat(
        [data_model, calculate_stochastic_oscillator(df['exchange_rate'], 9)], axis=1)
    data_model = pd.concat(
        [data_model, calculate_stochastic_oscillator(df['exchange_rate'], 14)], axis=1)
    data_model = pd.concat(
        [data_model, calculate_stochastic_oscillator(df['exchange_rate'], 23)], axis=1)
    data_model = pd.concat(
        [data_model, calculate_stochastic_oscillator(df['exchange_rate'], 37)], axis=1)
    data_model.dropna(inplace=True, axis=0)
    return data_model
    # print(indicators_df.head())


def calculate_moving_average(dataframe, win):
    ma = dataframe.rolling(window=win).mean().dropna(axis=0)
    return pd.Series(ma, name=f'MA_{win}')


def calculate_relative_strength_index(dataframe, window):
    delta = dataframe.diff()
    up = delta.where(delta > 0, 0)
    down = -delta.where(delta < 0, 0)
    ema_up = up.ewm(span=window, adjust=True,
                    ignore_na=True).mean().dropna(axis=0)
    ema_down = down.ewm(span=window, adjust=True,
                        ignore_na=True).mean().dropna(axis=0)
    avg_gain = up.rolling(window=window, min_periods=1).mean().dropna(axis=0)
    avg_loss = down.rolling(window=window, min_periods=1).mean().dropna(axis=0)
    rs_mva = avg_gain / avg_loss
    rs_ewm = ema_up / ema_down
    rsi_mva = 100 - (100 / (1 + rs_mva))
    rsi_ewm = 100 - (100 / (1 + rs_ewm))
    return pd.DataFrame({f"RSI_ewm_{window}": rsi_ewm, f"RSI_mva_{window}": rsi_mva}, index=dataframe.index)


def calculate_bollinger_bands(dataframe, window):
    ma = dataframe.rolling(window=window).mean().dropna(axis=0)
    std = dataframe.rolling(window=window).std().dropna(axis=0)
    upper_band = ma + (2 * std)
    lower_band = ma - (2 * std)
    return pd.DataFrame({f'bb_Upper_Band_{window}': upper_band, f'bb_Lower_Band_{window}': lower_band}, index=dataframe.index)


def calculate_stochastic_oscillator(dataframe, window):
    low = dataframe.rolling(window=window).min().dropna(axis=0)
    high = dataframe.rolling(window=window).max().dropna(axis=0)
    k = 100 * ((dataframe - low) / (high - low))
    d = k.rolling(window=3).mean()
    return pd.DataFrame({f'%K{window}': k, f'%D{window}': d}, index=dataframe.index)


model = tf.keras.Sequential()
model = create_lstm_model(model,n_steps, n_features)
df = pd.DataFrame(columns=['exchange_rate'])
scaler_2 = MinMaxScaler()
scaler_1 = StandardScaler()
x = [0] * n_steps
predictions_df = pd.DataFrame([x])
k = 1
while k:
    k += 1
    forex_exchange = get_exchange_rate(k)
    if not forex_exchange.empty:
        df = pd.concat([df, forex_exchange], axis=0).drop_duplicates()
        # df = df[~df.index.duplicated(keep='last')]  # Drop duplicate indices
        num_samples_1 = df.shape[0]
        if(num_samples_1 >= 141):
            data_model = create_data_model(df)
            df_scaled_1 = pd.DataFrame(scaler_1.fit_transform(
                data_model), columns=data_model.columns)
            df_scaled_2 = pd.DataFrame(scaler_2.fit_transform(
                df_scaled_1), columns=data_model.columns)
            print(df_scaled_2.shape)
            num_samples_2 = df_scaled_2.shape[0]
            if num_samples_2 >= (BATCH_SIZE):
                start_index = num_samples_2 - (BATCH_SIZE)
                features, labels = splitsequence(
                    df_scaled_2.iloc[start_index:, :], n_steps, n_features)
                print(features.shape, labels.shape)
                for _ in range(epoch):
                    model.train_on_batch(features, labels)
                x_ = df_scaled_2.iloc[num_samples_2-n_steps:,
                                      :].values.reshape(1, n_steps, n_features)
                predictions = np.array(model.predict(x_))
                # print(predictions[0])
                # plt.plot(predictions[0])
                # plt.show(block=False)
                # plt.pause(0.00001)
                predictions_df = pd.concat([predictions_df, pd.DataFrame(
                    predictions, columns=predictions_df.columns)], axis=0).drop_duplicates()
                plot_predictions(
                    predictions[0], df_scaled_2.iloc[-5*n_steps:, [0]])
                # predictions_df = predictions_df.append(pd.DataFrame(
                #     predictions, columns=predictions_df.columns), ignore_index=True)
                # if num_samples_2 % 5 == 4:
                # plt.plot(predictions_df.tail(20))
                # plt.show(block=False)
                # plt.pause(0.001)    # plt.show()
