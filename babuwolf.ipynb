{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/U-11-Agar/time_series_bots/blob/testing/babuwolf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Input, Bidirectional, LSTM, Attention, BatchNormalization, Dense,LeakyReLU,Dropout\n",
        "from keras.losses import mean_squared_error\n",
        "from keras.metrics import RootMeanSquaredError\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "BASE_URL = 'https://www.alphavantage.co/query?'\n",
        "API_KEY = 'K37TOUDE2WB29LQJ'\n",
        "\n",
        "BATCH_SIZE = 120\n",
        "TIME_DELAY = 20\n",
        "n_steps = 20\n",
        "n_features = 19  # We'll include the exchange rate and RSI as features\n",
        "epoch = 2\n",
        "k=0\n",
        "\n",
        "\n",
        "\n",
        "def get_exchange_rate(BASE_URL,API_KEY,k):\n",
        "    params = {\n",
        "        'function': 'CURRENCY_EXCHANGE_RATE',\n",
        "        'from_currency': \"BTC\",\n",
        "        'to_currency': \"USD\",\n",
        "        'apikey': API_KEY\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        return pd.DataFrame({'exchange_rate': np.random.rand()}, index=[k])\n",
        "    except Exception as e:\n",
        "        print(f'Error fetching forex exchange details: {e}')\n",
        "        return pd.DataFrame()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def lstm_model(model,n_steps,n_features):\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, input_shape=(n_steps, n_features), use_bias=True,activation=\"linear\")))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation='tanh',dropout=0.05)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation=LeakyReLU(alpha=0.1111),dropout=0.10)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation='tanh',dropout=0.20)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation=LeakyReLU(alpha=0.2222),dropout=0.20)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation='tanh',dropout=0.30)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation=LeakyReLU(alpha=0.3333),dropout=0.30)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation='tanh',dropout=0.40)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation=LeakyReLU(alpha=0.4444),dropout=0.40)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation='tanh',dropout=0.5555)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation=LeakyReLU(alpha=0.5555),dropout=0.50)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation='tanh',dropout=0.5555)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation=LeakyReLU(alpha=0.6666),dropout=0.40)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation='tanh',dropout=0.40)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation=LeakyReLU(alpha=0.7777),dropout=0.30)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation='tanh',dropout=0.30)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation=LeakyReLU(alpha=0.8888),dropout=0.20)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation='tanh',dropout=0.20)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation=LeakyReLU(alpha=0.9999),dropout=0.10)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation='tanh',dropout=0.05)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, use_bias=True,activation='linear',dropout=0.05)))\n",
        "  model.add(Dense(units=n_steps, activation='linear'))\n",
        "  model.compile(loss='mean_absolute_error', optimizer=Adam(0.5,clipnorm=0.000000051), metrics=['mse'], run_eagerly=True)\n",
        "  return model\n",
        "\n",
        "\n",
        "def splitsequence(data, n_steps, n_features):\n",
        "    X, y = [], []\n",
        "    for i in range(n_steps, data.shape[0]-n_steps):\n",
        "        X.append(data.iloc[i-n_steps:i, :].values)\n",
        "        y.append(data.iloc[i:i+n_steps, [0]].values)\n",
        "    X, y = np.array(X), np.array(y)\n",
        "    X = X.reshape(X.shape[0], n_steps, n_features)\n",
        "    y = y.reshape(y.shape[0], n_steps, 1)\n",
        "    return X, y\n",
        "\n",
        "def plot_predictions(predictions,data):\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.plot(data, color='red', label=\"exchange_rate\")\n",
        "    plt.plot(np.arange(len(data)-1, -1+len(data) + len(predictions)), predictions, color='green', label='future')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def create_data_model(df):\n",
        "  data_model = pd.DataFrame(df['exchange_rate'],index=df.index,columns=[\"exchange_rate\"])\n",
        "  data_model = pd.concat([data_model,calculate_moving_average(df['exchange_rate'],2)],axis=1)\n",
        "  data_model = pd.concat([data_model,calculate_moving_average(df['exchange_rate'],3)],axis=1)\n",
        "  data_model = pd.concat([data_model,calculate_moving_average(df['exchange_rate'],5)],axis=1)\n",
        "  data_model = pd.concat([data_model,calculate_moving_average(df['exchange_rate'],8)],axis=1)\n",
        "  data_model = pd.concat([data_model,calculate_moving_average(df['exchange_rate'],13)],axis=1)\n",
        "  data_model = pd.concat([data_model,calculate_moving_average(df['exchange_rate'],21)],axis=1)\n",
        "  data_model = pd.concat([data_model,calculate_relative_strength_index(df['exchange_rate'],9)],axis=1)\n",
        "  data_model = pd.concat([data_model,calculate_relative_strength_index(df['exchange_rate'],14)],axis=1)\n",
        "  data_model = pd.concat([data_model,calculate_bollinger_bands(df['exchange_rate'],10)],axis=1)\n",
        "  data_model = pd.concat([data_model,calculate_bollinger_bands(df['exchange_rate'],20)],axis=1)\n",
        "  data_model = pd.concat([data_model,calculate_stochastic_oscillator(df['exchange_rate'],9)],axis=1)\n",
        "  data_model = pd.concat([data_model,calculate_stochastic_oscillator(df['exchange_rate'],14)],axis=1)\n",
        "  data_model.dropna(inplace=True,axis=0)\n",
        "  return data_model\n",
        "    # print(indicators_df.head())\n",
        "\n",
        "def calculate_moving_average(dataframe, win):\n",
        "    ma = dataframe.rolling(window=win).mean().dropna(axis=0)\n",
        "    return pd.Series(ma, name=f'MA_{win}')\n",
        "\n",
        "def calculate_relative_strength_index(dataframe, window):\n",
        "    delta = dataframe.diff()\n",
        "    up = delta.where(delta > 0, 0)\n",
        "    down = -delta.where(delta < 0, 0)\n",
        "    ema_up = up.ewm(span=window, adjust=True,ignore_na=True).mean().dropna(axis=0)\n",
        "    ema_down = down.ewm(span=window, adjust=True,ignore_na=True).mean().dropna(axis=0)\n",
        "    avg_gain = up.rolling(window=window, min_periods=1).mean().dropna(axis=0)\n",
        "    avg_loss = down.rolling(window=window, min_periods=1).mean().dropna(axis=0)\n",
        "    rs_mva = avg_gain / avg_loss\n",
        "    rs_ewm = ema_up / ema_down\n",
        "    rsi_mva = 100 - (100 / (1 + rs_mva))\n",
        "    rsi_ewm = 100 - (100 / (1 + rs_ewm))\n",
        "    return pd.DataFrame({f\"RSI_ewm_{window}\": rsi_ewm,f\"RSI_mva_{window}\":rsi_mva},index=dataframe.index)\n",
        "\n",
        "def calculate_bollinger_bands(dataframe, window):\n",
        "    ma = dataframe.rolling(window=window).mean().dropna(axis=0)\n",
        "    std = dataframe.rolling(window=window).std().dropna(axis=0)\n",
        "    upper_band = ma + (2 * std)\n",
        "    lower_band = ma - (2 * std)\n",
        "    return pd.DataFrame({f'bb_Upper_Band_{window}': upper_band, f'bb_Lower_Band_{window}': lower_band},index=dataframe.index)\n",
        "\n",
        "def calculate_stochastic_oscillator(dataframe, window):\n",
        "    low = dataframe.rolling(window=window).min().dropna(axis=0)\n",
        "    high = dataframe.rolling(window=window).max().dropna(axis=0)\n",
        "    k = 100 * ((dataframe - low) / (high - low))\n",
        "    d = k.rolling(window=3).mean()\n",
        "    return pd.DataFrame({f'%K{window}': k, f'%D{window}': d},index=dataframe.index)"
      ],
      "metadata": {
        "id": "OCNoocsRqGJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model = lstm_model(model,n_steps,n_features)\n",
        "df = pd.DataFrame(columns=['exchange_rate'])\n",
        "scaler_1=MinMaxScaler()\n",
        "scaler_2=StandardScaler()\n",
        "x = [0] * n_steps\n",
        "predictions_df = pd.DataFrame([x])\n",
        "k=1\n",
        "while k:\n",
        "    k+=1\n",
        "    forex_exchange = get_exchange_rate(BASE_URL,API_KEY,k)\n",
        "    if not forex_exchange.empty:\n",
        "        df = pd.concat([df, forex_exchange], axis=0).drop_duplicates()\n",
        "        # df = df[~df.index.duplicated(keep='last')]  # Drop duplicate indices\n",
        "        num_samples_1 = df.shape[0]\n",
        "        if(num_samples_1>=141):\n",
        "          data_model = create_data_model(df)\n",
        "          df_scaled_1=pd.DataFrame(scaler_1.fit_transform(data_model),columns=data_model.columns)\n",
        "          df_scaled_2=pd.DataFrame(scaler_2.fit_transform(df_scaled_1),columns=data_model.columns)\n",
        "          print(df_scaled_2.shape)\n",
        "          num_samples_2 = df_scaled_2.shape[0]\n",
        "          if num_samples_2 >= (BATCH_SIZE):\n",
        "              start_index = num_samples_2 - (BATCH_SIZE)\n",
        "              features, labels = splitsequence(df_scaled_2.iloc[start_index:, :], n_steps, n_features)\n",
        "              print(features, labels)\n",
        "              for _ in range(epoch):\n",
        "                  model.train_on_batch(features, labels)\n",
        "              x_ = df_scaled_2.iloc[num_samples_2-n_steps:,:].values.reshape(1, n_steps, n_features)\n",
        "              predictions = np.array(model.predict(x_))\n",
        "              print(predictions[0])\n",
        "              predictions_df = predictions_df.append(pd.DataFrame(predictions,columns=predictions_df.columns), ignore_index=True)\n",
        "              if num_samples_2 % 5 == 0:\n",
        "                plt.plot(predictions_df.tail(20))"
      ],
      "metadata": {
        "id": "6sf9YR7AqGCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "df = pd.DataFrame(columns=['exchange_rate'])\n",
        "def get_exchange_rate(k, noise_level=np.random.randn(), trend=np.random.randn()):\n",
        "    # Assuming you want to generate synthetic exchange rate data using a sine wave\n",
        "    # with some added noise and trend.\n",
        "    # k: index for generating new data point\n",
        "    # noise_level: magnitude of noise to be added\n",
        "    # trend: linear trend added to the data\n",
        "\n",
        "    # Frequency of the sine wave (in cycles per unit time)\n",
        "    freq = 0.1\n",
        "\n",
        "    # Amplitude of the sine wave\n",
        "    amplitude = 100\n",
        "\n",
        "    # Generate time series data using sine wave\n",
        "    exchange_rate = amplitude * np.sin(freq * k) + trend * k\n",
        "\n",
        "    # Add noise to the data\n",
        "    exchange_rate += noise_level * np.random.randn()\n",
        "\n",
        "    # Return the synthetic exchange rate data\n",
        "    return pd.DataFrame({'exchange_rate': exchange_rate}, index=[k])\n",
        "\n",
        "# Example usage:\n",
        "for k in range(100):\n",
        "    forex_exchange = get_exchange_rate(k)\n",
        "    if not forex_exchange.empty:\n",
        "        df = pd.concat([df, forex_exchange], axis=0).drop_duplicates()\n",
        "print(df)\n",
        "plt.plot(df)\n"
      ],
      "metadata": {
        "id": "4RwA9xr5MnPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.rand()"
      ],
      "metadata": {
        "id": "TPVowE7dONJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.linspace(0, 10, 1000)"
      ],
      "metadata": {
        "id": "UpYiIJdmM6Zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = [0]*n_steps\n",
        "[x]"
      ],
      "metadata": {
        "id": "giHyN4Rx5liG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k+=1\n",
        "forex_exchange = get_exchange_rate(BASE_URL,API_KEY,k)\n",
        "if not forex_exchange.empty:\n",
        "    df = pd.concat([df, forex_exchange], axis=0).drop_duplicates()\n",
        "print(df)"
      ],
      "metadata": {
        "id": "f01TP-_Xzx9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7owK9YNCZbvB"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Input, Bidirectional, LSTM, Attention, BatchNormalization, Dense,LeakyReLU,Dropout\n",
        "from keras.losses import mean_squared_error\n",
        "from keras.metrics import RootMeanSquaredError\n",
        "# from keras.initializers import RandomUniform\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "BASE_URL = 'https://www.alphavantage.co/query?'\n",
        "API_KEY = 'K37TOUDE2WB29LQJ'\n",
        "\n",
        "BATCH_SIZE = 120\n",
        "TIME_DELAY = 20\n",
        "n_steps = 20\n",
        "n_features = 19  # We'll include the exchange rate and RSI as features\n",
        "epoch = 2\n",
        "k=0\n",
        "import pandas as pd\n",
        "def get_exchange_rate(BASE_URL,API_KEY,k):\n",
        "    params = {\n",
        "        'function': 'CURRENCY_EXCHANGE_RATE',\n",
        "        'from_currency': \"BTC\",\n",
        "        'to_currency': \"USD\",\n",
        "        'apikey': API_KEY\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # response = requests.get(BASE_URL, params=params)\n",
        "        # data = response.json()\n",
        "        # k+=1\n",
        "        # x=data['Realtime Currency Exchange Rate']\n",
        "        # return pd.DataFrame({'exchange_rate':np.random.rand()},index = [k])\n",
        "        # return pd.DataFrame({'exchange_rate':x['5. Exchange Rate']},index = [pd.to_datetime(x['6. Last Refreshed'])])\n",
        "        return pd.DataFrame({'exchange_rate': np.random.rand()}, index=[k])\n",
        "    except Exception as e:\n",
        "        print(f'Error fetching forex exchange details: {e}')\n",
        "        return pd.DataFrame()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def lstm_model(model,n_steps,n_features):\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, input_shape=(n_steps, n_features), use_bias=True,activation=\"linear\")))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation='tanh',dropout=0.05)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation=LeakyReLU(alpha=0.1111),dropout=0.10)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation='tanh',dropout=0.05)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation=LeakyReLU(alpha=0.2222),dropout=0.20)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation='tanh',dropout=0.05)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation=LeakyReLU(alpha=0.3333),dropout=0.30)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation='tanh',dropout=0.05)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation=LeakyReLU(alpha=0.4444),dropout=0.40)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation='tanh',dropout=0.05)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation=LeakyReLU(alpha=0.5555),dropout=0.50)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation='tanh',dropout=0.05)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation=LeakyReLU(alpha=0.6666),dropout=0.40)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation='tanh',dropout=0.05)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation=LeakyReLU(alpha=0.7777),dropout=0.30)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation='tanh',dropout=0.05)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation=LeakyReLU(alpha=0.8888),dropout=0.20)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation='tanh',dropout=0.05)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation=LeakyReLU(alpha=0.9999),dropout=0.10)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, return_sequences=True, use_bias=True,activation='tanh',dropout=0.05)))\n",
        "  model.add(Bidirectional(LSTM(units=BATCH_SIZE, use_bias=True,activation='linear',dropout=0.05)))\n",
        "  model.add(Dense(units=n_steps, activation='linear'))\n",
        "  # model.compile(loss='Binary_cr', optimizer=Adam(0.001,clipnorm=0.01), metrics=['accuracy','mse','mae'])\n",
        "  model.compile(loss='mean_absolute_error', optimizer=Adam(0.05,clipnorm=0.00000051), metrics=['mse'], run_eagerly=True)\n",
        "  # model.compile(optimizer='adam', loss=mean_squared_error)\n",
        "  return model\n",
        "\n",
        "\n",
        "def splitsequence(data, n_steps, n_features):\n",
        "    # The function to split data into sequences for LSTM training remains the same\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in np.arange(n_steps, (len(data)-n_steps)):\n",
        "        X.append(data.iloc[i-n_steps:i, :].values)\n",
        "        y.append(data.loc[i:i+(n_steps-1),[\"exchange_rate\"]].values)\n",
        "    X, y = np.array(X), np.array(y)\n",
        "    X = X.reshape(X.shape[0], n_steps, n_features)\n",
        "    y = y.reshape(y.shape[0], n_steps, 1)\n",
        "    return X, y\n",
        "\n",
        "def plot_predictions(predictions,data):\n",
        "    # plt.figure(figsize=(20, 10))\n",
        "    # # plt.plot(predictions_df['real_value'], label='Real Value')\n",
        "    # # plt.show()\n",
        "    # plt.plot(data,color='red',lable=\"exchange_rate\")\n",
        "    # plt.plot(np.array(data)+predictions_df,color='green',lable='future')\n",
        "    # plt.show()\n",
        "    # # plt.xlabel('Time')\n",
        "    # # plt.ylabel('Exchange Rate')\n",
        "    # # plt.title('Real vs Predicted Exchange Rate')\n",
        "    # # plt.legend()\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.plot(data, color='red', label=\"exchange_rate\")\n",
        "    plt.plot(np.arange(len(data)-1, -1+len(data) + len(predictions)), predictions, color='green', label='future')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def create_data_model(df):\n",
        "  data_model = pd.DataFrame(df['exchange_rate'],index=df.index,columns=[\"exchange_rate\"])\n",
        "  data_model = pd.concat([data_model,calculate_moving_average(df['exchange_rate'],2)],axis=1)\n",
        "  data_model = pd.concat([data_model,calculate_moving_average(df['exchange_rate'],3)],axis=1)\n",
        "  data_model = pd.concat([data_model,calculate_moving_average(df['exchange_rate'],5)],axis=1)\n",
        "  data_model = pd.concat([data_model,calculate_moving_average(df['exchange_rate'],8)],axis=1)\n",
        "  data_model = pd.concat([data_model,calculate_moving_average(df['exchange_rate'],13)],axis=1)\n",
        "  data_model = pd.concat([data_model,calculate_moving_average(df['exchange_rate'],21)],axis=1)\n",
        "  data_model = pd.concat([data_model,calculate_relative_strength_index(df['exchange_rate'],9)],axis=1)\n",
        "  data_model = pd.concat([data_model,calculate_relative_strength_index(df['exchange_rate'],14)],axis=1)\n",
        "  data_model = pd.concat([data_model,calculate_bollinger_bands(df['exchange_rate'],10)],axis=1)\n",
        "  data_model = pd.concat([data_model,calculate_bollinger_bands(df['exchange_rate'],20)],axis=1)\n",
        "  data_model = pd.concat([data_model,calculate_stochastic_oscillator(df['exchange_rate'],9)],axis=1)\n",
        "  data_model = pd.concat([data_model,calculate_stochastic_oscillator(df['exchange_rate'],14)],axis=1)\n",
        "  data_model.dropna(inplace=True,axis=0)\n",
        "  return data_model\n",
        "    # print(indicators_df.head())\n",
        "\n",
        "\n",
        "def calculate_moving_average(dataframe, win):\n",
        "    ma = dataframe.rolling(window=win).mean().dropna(axis=0)\n",
        "    return pd.Series(ma, name=f'MA_{win}')\n",
        "\n",
        "\n",
        "def calculate_relative_strength_index(dataframe, window):\n",
        "    delta = dataframe.diff()\n",
        "    up = delta.where(delta > 0, 0)\n",
        "    down = -delta.where(delta < 0, 0)\n",
        "    ema_up = up.ewm(span=window, adjust=True,ignore_na=True).mean().dropna(axis=0)\n",
        "    ema_down = down.ewm(span=window, adjust=True,ignore_na=True).mean().dropna(axis=0)\n",
        "    avg_gain = up.rolling(window=window, min_periods=1).mean().dropna(axis=0)\n",
        "    avg_loss = down.rolling(window=window, min_periods=1).mean().dropna(axis=0)\n",
        "    rs_mva = avg_gain / avg_loss\n",
        "    rs_ewm = ema_up / ema_down\n",
        "    rsi_mva = 100 - (100 / (1 + rs_mva))\n",
        "    rsi_ewm = 100 - (100 / (1 + rs_ewm))\n",
        "    return pd.DataFrame({f\"RSI_ewm_{window}\": rsi_ewm,f\"RSI_mva_{window}\":rsi_mva},index=dataframe.index)\n",
        "\n",
        "def calculate_bollinger_bands(dataframe, window):\n",
        "    ma = dataframe.rolling(window=window).mean().dropna(axis=0)\n",
        "    std = dataframe.rolling(window=window).std().dropna(axis=0)\n",
        "    upper_band = ma + (2 * std)\n",
        "    lower_band = ma - (2 * std)\n",
        "    return pd.DataFrame({f'bb_Upper_Band_{window}': upper_band, f'bb_Lower_Band_{window}': lower_band},index=dataframe.index)\n",
        "\n",
        "def calculate_stochastic_oscillator(dataframe, window):\n",
        "    low = dataframe.rolling(window=window).min().dropna(axis=0)\n",
        "    high = dataframe.rolling(window=window).max().dropna(axis=0)\n",
        "    k = 100 * ((dataframe - low) / (high - low))\n",
        "    d = k.rolling(window=3).mean()\n",
        "    return pd.DataFrame({f'%K{window}': k, f'%D{window}': d},index=dataframe.index)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model = lstm_model(model,n_steps,n_features)\n",
        "df = pd.DataFrame(columns=['exchange_rate'])\n",
        "scaler=MinMaxScaler()\n",
        "# scaler=StandardScaler()\n",
        "x=[i for i in range(n_steps)]\n",
        "predictions_df = pd.DataFrame([x])\n",
        "k=1\n",
        "while k:\n",
        "    k+=1\n",
        "    forex_exchange = get_exchange_rate(BASE_URL,API_KEY,k)\n",
        "    if not forex_exchange.empty:\n",
        "        df = pd.concat([df, forex_exchange], axis=0).drop_duplicates()\n",
        "        df = df[~df.index.duplicated(keep='last')]  # Drop duplicate indices\n",
        "        num_samples_1 = df.shape[0]\n",
        "        if(num_samples_1>=140):\n",
        "          data_model = create_data_model(df)\n",
        "          df_scaled_model=pd.DataFrame(scaler.fit_transform(data_model),columns=data_model.columns)\n",
        "          print(df_scaled_model.shape)\n",
        "          num_samples_2 = df_scaled_model.shape[0]\n",
        "          if num_samples_2 >= (BATCH_SIZE):\n",
        "              start_index = num_samples_2 - (BATCH_SIZE)\n",
        "\n",
        "              # if predictions_df.shape[0] != 0:\n",
        "              #     predictions_df.iloc[-1, 0] = df_scaled_model['exchange_rate'].iloc[-2]\n",
        "              #     predictions_df.iloc[-1, 2] = abs(df_scaled_model['exchange_rate'].iloc[-2] - predictions_df.iloc[-1, 1])\n",
        "\n",
        "\n",
        "              features, labels = splitsequence(df_scaled_model.iloc[start_index:, :], n_steps, n_features)\n",
        "\n",
        "              for _ in range(epoch):\n",
        "                  model.train_on_batch(features, labels)\n",
        "\n",
        "              x_ = df_scaled_model.iloc[num_samples_2-n_steps:,:].values.reshape(1, n_steps, n_features)\n",
        "              predictions = np.array(model.predict(x_))\n",
        "              print(predictions[0])\n",
        "\n",
        "              # plot_predictions(predictions[0],df_scaled_model['exchange_rate'])\n",
        "              # plot_predictions(predictions[0], df_scaled_model['exchange_rate'])\n",
        "\n",
        "\n",
        "              # new_predictions = {\n",
        "              #     # 'real_value': np.nan,\n",
        "              #     'predicted_value': predictions,\n",
        "              #     # 'absolute_error': np.nan,\n",
        "              #     # 'rsi': calculate_relative_strength_index(pd.DataFrame(predictions), 5)\n",
        "              # }\n",
        "\n",
        "              predictions_df = predictions_df.append(pd.DataFrame(predictions,columns=predictions_df.columns), ignore_index=True)\n",
        "              if num_samples_2 % 5 == 4:\n",
        "                plt.plot(predictions_df.tail(20))\n",
        "              # print(predictions_df)\n",
        "\n",
        "              # # Use the LSTM predictions and RSI for buy/sell decisions\n",
        "              # if len(predictions_df) > n_steps:\n",
        "              #     # Assuming the LSTM predicts price increase and RSI is oversold, we'll buy, and vice versa\n",
        "              #     if (predictions_df.iloc[-1]['predicted_value'] > predictions_df.iloc[-2]['predicted_value']) and (predictions_df.iloc[-1]['rsi'] < 30):\n",
        "              #         print(f\"Buying at {df.index[-1]}\")\n",
        "              #         # Place buy order using your trading API\n",
        "              #         # r.orders.order_buy_market(SYMBOL, 1, timeInForce='gfd')\n",
        "              #     elif (predictions_df.iloc[-1]['predicted_value'] < predictions_df.iloc[-2]['predicted_value']) and (predictions_df.iloc[-1]['rsi'] > 70):\n",
        "              #         print(f\"Selling at {df.index[-1]}\")\n",
        "              #         # Place sell order using your trading API\n",
        "              #         # r.orders.order_sell_market(SYMBOL, 1, timeInForce='gfd')\n",
        "\n",
        "              # time.sleep(0.33)\n",
        "    # else:\n",
        "        # time.sleep(0.33)\n"
      ],
      "metadata": {
        "id": "-0daUs7dTGBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(features.shape, labels.shape)"
      ],
      "metadata": {
        "id": "Pz69g20UmeJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZfHrvs6ogvSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_scaled_model.describe()"
      ],
      "metadata": {
        "id": "aTuu6gUBeBgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=[i for i in range(n_steps)]\n",
        "predictions_df = pd.DataFrame([x])\n",
        "predictions_df = predictions_df.append(pd.DataFrame([x],columns=predictions_df.columns), ignore_index=True)\n",
        "print(predictions_df)"
      ],
      "metadata": {
        "id": "_Dxu7v5DTMj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(np.array(df_scaled_model['exchange_rate']).reshape(df_scaled_model.shape[0],1))"
      ],
      "metadata": {
        "id": "RE6dPzUpWMon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.arange(len(df_scaled_model['exchange_rate']), len(df_scaled_model['exchange_rate']) + len(predictions))"
      ],
      "metadata": {
        "id": "YkfZ12INYbvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_predictions(predictions, data):\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    plt.plot(data, color='red', label=\"exchange_rate\")\n",
        "    plt.plot(np.arange(len(data)-1, -1+len(data) + len(predictions)), predictions, color='green', label='future')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Assuming you have 'predictions' and 'df_scaled_model['exchange_rate']'\n",
        "# Replace these with your actual data\n",
        "predictions = [[10, 15, 12, 8, 6]]  # Example data for predictions\n",
        "df_scaled_model = pd.DataFrame({'exchange_rate': [5, 8, 10, 9, 11]})  # Example data for exchange_rate\n",
        "\n",
        "plot_predictions(predictions[0], df_scaled_model['exchange_rate'])\n"
      ],
      "metadata": {
        "id": "YLvuNTpUYCog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions(predictions,data):\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    # plt.plot(predictions_df['real_value'], label='Real Value')\n",
        "    # plt.show()\n",
        "    plt.plot(data,color='red',label=\"exchange_rate\")\n",
        "    plt.plot(plt.plot(np.array(data).reshape(data.shape[0],1))+predictions,color='green',label='future')\n",
        "    plt.show()\n",
        "    # plt.xlabe\n",
        "plot_predictions(predictions[0],df_scaled_model['exchange_rate'])"
      ],
      "metadata": {
        "id": "SpTfzUpxPhKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "id": "onnl_290XHee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(data).reshape(1,data.shape[0])+[predictions]"
      ],
      "metadata": {
        "id": "ZyXBuK3JXDlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have two arrays 'x' and 'y'\n",
        "x = [1, 2, 3, 4, 5]\n",
        "y = [10, 15, 12, 8, 6]\n",
        "\n",
        "# Plot the 'x' array first\n",
        "plt.plot(x+y, label='X')\n",
        "\n",
        "# Plot the 'y' array after the 'x' array\n",
        "# plt.plot(y, label='Y')  # This plot is used for creating the label only\n",
        "\n",
        "# Show the legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QuxrXazmTPdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=df_scaled_model.loc[:,[\"exchange_rate\"]].values\n",
        "y=prediction\n",
        "# plt.plot(df_scaled_model.loc[:,[\"exchange_rate\"]].values)"
      ],
      "metadata": {
        "id": "yQeUQW0SSJkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(features.shape, labels.shape)\n",
        "\n",
        "plt.plot(predictions[0])"
      ],
      "metadata": {
        "id": "15jiP27JmMhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df = predictions_df.append({\"predicted_value\":predictions.reshape(n_steps,1)}, ignore_index=True)\n",
        "print(predictions_df)"
      ],
      "metadata": {
        "id": "vkiD-32lMFZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,4,5,6,7,8,9]\n",
        "df=pd.DataFrame([x],)\n",
        "df"
      ],
      "metadata": {
        "id": "FXGSpgCpMUJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.DataFrame()\n",
        "for i in range(100):\n",
        "  forex_exchange=x(i)\n",
        "  df = pd.concat([df, forex_exchange],axis=0).drop_duplicates()\n",
        "  df.index.drop_duplicates()\n",
        "  num_samples_1 = df.shape[0]\n",
        "  print(num_samples_1)\n",
        "print(df)\n",
        "data=df\n",
        "X = []\n",
        "y = []\n",
        "for i in np.arange(20, (len(data)-20)):\n",
        "    X.append(data.iloc[i-20:i, :].values)\n",
        "    y.append(data.loc[i:i+20,[\"exchange_rate\"]].values)\n",
        "X, y = np.array(X), np.array(y)\n",
        "X = X.reshape(X.shape[0], n_steps, n_features)\n",
        "# y = y.reshape(y.shape[0], n_steps, 1)\n",
        "print(X,y)"
      ],
      "metadata": {
        "id": "epT3n0msmMec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.arange(20,len(data)-20)"
      ],
      "metadata": {
        "id": "fdshnyGqmMbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.loc[0:20,[\"exchange_rate\"]]"
      ],
      "metadata": {
        "id": "6Y1E8iBQmMWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=[]\n",
        "y=[]\n",
        "for i in np.arange(n_steps, (len(data)-n_steps+1)):\n",
        "    X.append(data.iloc[i-n_steps:i, :].values)\n",
        "    y.append(data.loc[i:i+(n_steps-1),[\"exchange_rate\"]].values)"
      ],
      "metadata": {
        "id": "-XgMWHa4mMTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DPZMgyhtmMMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_scaled_model.shape"
      ],
      "metadata": {
        "id": "xIIMqM9YCW2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k=[1]\n",
        "k+=[1]\n",
        "print(k)"
      ],
      "metadata": {
        "id": "hXniX-DwWQ-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def x(i):\n",
        "  # for i in range(10):\n",
        "    # i+=1\n",
        "    # x=data['Realtime Currency Exchange Rate']\n",
        "    return pd.DataFrame({'exchange_rate':np.random.rand()},index = [i])"
      ],
      "metadata": {
        "id": "U53V2tqRUkj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(100):\n",
        "  forex_exchange=x(i)\n",
        "  df = pd.concat([df, forex_exchange],axis=0).drop_duplicates()\n",
        "  df.index.drop_duplicates()\n",
        "  num_samples_1 = df.shape[0]\n",
        "  print(num_samples_1)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "9-WO9gccZJLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def x(i):\n",
        "    return pd.DataFrame({'exchange_rate': np.random.rand()}, index=[i])\n",
        "\n",
        "# Initialize an empty DataFrame\n",
        "df = pd.DataFrame()\n",
        "\n",
        "num_samples_list = []\n",
        "\n",
        "for i in range(10):\n",
        "    forex_exchange = x(i)\n",
        "    df = pd.concat([df, forex_exchange], axis=0).drop_duplicates()\n",
        "    df = df[~df.index.duplicated(keep='last')]  # Drop duplicate indices\n",
        "    num_samples = df.shape[0]\n",
        "    num_samples_list.append(num_samples)\n",
        "    # print(num_samples)\n",
        "\n",
        "print(df)\n",
        "print(num_samples_list)\n",
        "\n"
      ],
      "metadata": {
        "id": "zcJdf_sPaHOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in np.arange(10, 20):\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "MsMjG8AGbtSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[0:6]"
      ],
      "metadata": {
        "id": "1B-ulSOMo4zS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pcBF89nzk-TJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}